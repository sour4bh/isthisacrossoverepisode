{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Sofwares\\Anaconda\\lib\\site-packages\\deap\\tools\\_hypervolume\\pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PrimitiveSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2f0395243323>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mpset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPrimitiveSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MAIN\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mpset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddPrimitive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mpset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddPrimitive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PrimitiveSet' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import gp\n",
    "from deap import tools\n",
    "\n",
    "\n",
    "\n",
    "pset = PrimitiveSet(\"MAIN\", 2)\n",
    "pset.addPrimitive(max, 2)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addTerminal(3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pset.addPrimitive(operator.neg, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "expr = genFull(pset, min_=1, max_=3)\n",
    "tree = PrimitiveTree(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add(add(max(nn, add(add(4, bn), 4)), max(thickness, thickness)), max(add(ma, bc), max(mitoses, bn)))\n",
      "max(mul(mul(shape, bn), mul(se, 4)), mul(max(size, ma), add(bc, shape)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Sofwares\\Anaconda\\lib\\site-packages\\deap\\creator.py:141: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "E:\\Sofwares\\Anaconda\\lib\\site-packages\\deap\\creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from binarytree import Node,build\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import gp\n",
    "from deap import tools\n",
    "\n",
    "\n",
    "pset = gp.PrimitiveSet(\"main\", 9)\n",
    "pset.addPrimitive(max, 2)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "a=4\n",
    "pset.addTerminal(4)\n",
    "\n",
    "\n",
    "pset.renameArguments(ARG0=\"thickness\")\n",
    "pset.renameArguments(ARG1=\"size\")\n",
    "pset.renameArguments(ARG2=\"shape\")\n",
    "pset.renameArguments(ARG3=\"ma\")\n",
    "pset.renameArguments(ARG4=\"se\")\n",
    "pset.renameArguments(ARG5=\"bn\")\n",
    "pset.renameArguments(ARG6=\"bc\")\n",
    "pset.renameArguments(ARG7=\"nn\")\n",
    "pset.renameArguments(ARG8=\"mitoses\")\n",
    "\n",
    "\n",
    "expr = gp.genFull(pset, min_=1, max_=5)\n",
    "tree = gp.PrimitiveTree(expr)\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin,\n",
    "               pset=pset)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=3, max_=5)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual,\n",
    "                 toolbox.expr)\n",
    "\n",
    "\n",
    "\n",
    "toolbox.register(\"row\", tools.initRepeat, list, toolbox.individual, n=10)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.row, n=10)\n",
    "\n",
    "\n",
    "\n",
    "x=toolbox.population()\n",
    "print(x[1][1])\n",
    "print(x[9][9])\n",
    "\n",
    "tree = gp.PrimitiveTree(expr)\n",
    "\n",
    "function = gp.compile(str(x[9][9]), pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "data = pd.read_csv('Dataset_MLAI.txt',sep = ',',header = None)\n",
    "#display(data)\n",
    "data[6] =  pd.to_numeric(data[6], errors='coerce') \n",
    "# drop nas\n",
    "data = data.dropna()\n",
    "\n",
    "x_features = data.iloc[:,1:10]\n",
    "y_features = data.iloc[:,10]\n",
    "y_list = list(y_features.values.T.ravel())\n",
    "x_array = x_features.values\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=42,shuffle = True)\n",
    "# print(x_train)\n",
    "x_train2, x_test, y_train2, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "# print(x_train)\n",
    "x_train3, x_test, y_train3, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "# print(x_train)\n",
    "x_train4, x_test, y_train4, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "# print(x_train)\n",
    "x_train5, x_test, y_train5, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "# print(x_train)\n",
    "x_train6, x_test, y_train6, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "# print(x_train)\n",
    "x_train7, x_test, y_train7, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "# print(len(x_train))\n",
    "x_train8, x_test, y_train8, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "# print(len(x_train))\n",
    "x_train9, x_test, y_train9, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "# print(len(x_train))\n",
    "x_train10, x_test, y_train10, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "print(len(x_train10))\n",
    "x_train11, x_test, y_train11, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "x_train12, x_test, y_train12, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "x_train13, x_test, y_train13, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "x_train14, x_test, y_train14, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "x_train15, x_test, y_train15, y_test = train_test_split(x_array, y_list, test_size=0.955, random_state=random.randint(1,100),shuffle = True)\n",
    "\n",
    "\n",
    "#print(X[0:5,:])\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_X = scaler.fit_transform(x_train)\n",
    "\n",
    "\n",
    "l=[]\n",
    "for i in range(30):\n",
    "    function = gp.compile(str(x[1][1]), pset)\n",
    "    if(function(scaled_X[i,0],scaled_X[i,1],scaled_X[i,2],scaled_X[i,3],scaled_X[i,4],scaled_X[i,5],scaled_X[i,6],scaled_X[i,7],scaled_X[i,8])<0):\n",
    "        l.append(4)\n",
    "    else:\n",
    "        l.append(2)\n",
    "print(l)\n",
    "\n",
    "\n",
    "# summarize transformed data\n",
    "\n",
    "#print(rescaledX[0:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
